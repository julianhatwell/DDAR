---
title: "Discrete Data Analysis"
subtitle: "A Friendly Guide to Visualising Categorical Data for Machine Learning Practitioners"
author: "Julian Hatwell"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  beamer_presentation:
    colortheme: "seahorse"
    fonttheme: "structurebold"
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(warning = FALSE
              , message = FALSE
              , echo = FALSE
              )

library(lattice)
library(ggplot2)
library(vcd)
library(vcdExtra)
library(ca)
library(randomForest)
library(ROSE)
```

# Introduction


## About You

Researchers, Analysts and Knowledge Professionals who

* have some experience of classification on tabular data sets
* understand different data-types (continuous, nominal, ordinal, count, etc...)
* are aware of ML project life-cycle, in particular:
    * Exploratory Data Analysis
    * Classification
    * Evaluating models
* know a little stats (you know what a $\chi^2$ test is)
* have read the introductory notes

## About Me

* Over 15 years in enterprise systems, management information systems and BI in the for-profit education sector, UK and Singapore
* MSc (Distinction) Business Intelligence, Birmingham City University, 2016-17
* Research to PhD (in progress), DAAI, Birmingham City University

## Enterprise Systems in Educational Institutions

```{r acad_sys, fig.align='center', fig.cap='High-level architecture of integrated academic systems. Paulsen, M. (2002 : p4) Online Education Systems: Discussion and Definition of Terms'}
include_graphics("acadsys.png", dpi = 175)
```

## Academic Analytics

* Academic Analytics
    * Typical BI analysis of sales (recruitment), financial, HR, operations, etc
    * Additionally, monitor, evaluate and optimise:
        * student life-cycle: from prospectus to alumni services
        * recruitment, including best match student-course
        * retention, minimising drop outs
        * on-time / on-target completion
        * progression to next level
        * student satisfaction, surveys
        * class room utilisation and exam planning
        * lecturer management, including externals
        
Not the same as

* Educational Data Mining
    * Analysis of pedogogical data (teaching and learning)
    * Student engagement data
    * Models of student understanding and learning
    * Topic modeling

## Aim and Objectives

Tips from the Trenches

* Share Practical Experience
* Relevant to ML project life-cycle
* Build intuition
* Focus on visual analytics
* Plain English
* By example
* Avoid theory and formulas
* Simple, reproducible code

## Head and tail activities:

* Developing a better EDA strategy for categorical data sets
* Exploring classification results in more detail
* Correct handling of ordinal classification results

## Credits

**Michael Friendly** is a pioneer in this field and has contributed to the development of modules and libraries for SAS and R.

Code examples based on material contained in the book [**Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data**](https://www.crcpress.com/Discrete-Data-Analysis-with-R-Visualization-and-Modeling-Techniques-for/Friendly-Meyer/p/book/9781498725835) by Michael Friendly and David Meyer.

Shorter, valuable tutorial on these topics in the [vcd vignette](https://cran.r-project.org/web/packages/vcdExtra/vignettes/vcd-tutorial.pdf). Just type **vignette("vcd")** at the R console.

This **video** https://www.youtube.com/watch?v=qfNsoc7Tf60 is a much more in depth lecture, by Michael Friendly, on topics covered in the book.

# Example One: Exploring Data with Area Based Plots

## Why is Exploratory Analysis so Important?

"Get to know" the data. This always pays off:

* Get rid of noise variables
* Identify most useful variables early
* Guide model selection
* Identify anomalies
* Develop intuition prior to modeling
* Develop a research question, if you don't have one

## In 3D with Hair Colour, Eye Colour and Gender

592 stats students, self-categorised, University of Delaware, 1974

```{r describe_haireye, echo=FALSE}
hr_desc <- data.frame(No=1:3
                      , Name=c("Hair", "Eye", "Sex")
                      , Levels=c("Black, Brown, Red, Blond", "Brown, Hazel, Green, Blue", "Male, Female"))
kable(hr_desc)
```

## Hard to Parse Lots of Numbers

```{r HEC}
HEC <- HairEyeColor[, c("Brown", "Hazel", "Green", "Blue"), ]

structable(~Sex+Hair+Eye, HEC)
```

## What You See Depends on the Pivot

```{r HEC_piv}
structable(~Hair+Sex+Eye, HEC)
```

## Naive Approach: Barplot in 2-D (ignoring Sex)

You're forced to favour one variable over the other. Does hair colour depend on eye colour?

```{r not_intuitive, fig.width = 6, fig.height = 4}
haireye <- margin.table(HEC, 1:2)
barplot(haireye, beside = TRUE, legend = TRUE)
```

***

Or does eye colour depend on hair colour? Comparing between groups is tricky.

```{r not_intuitive2, fig.width = 6, fig.height = 5}
# pivot the other way
barplot(aperm(haireye, 2:1), beside = TRUE, legend = TRUE)
```

## Tile Plot - Preserve Table Structure

```{r tiles, echo=TRUE, fig.width = 6, fig.height = 3.5}
# vcd package: one line of code!
# (table haireye prepared earlier)
tile(haireye) 
```

## $H_0$: No Association Between Hair and Eye

```{r hr_chisq}
chisq.test(haireye)
```

Rejected, obviously. There clearly is a relationship.

$\chi^2$ test gives no details. How to describe it?

## Mosaic Plot - Hair Marginal Totals

```{r hmt}
mosaic(margin.table(haireye, 1)
       , shade = TRUE
       , main="Hair Marginal Totals"
       , labeling = labeling_values
       , value_type = "observed"
       , gp_text = gpar(fontface = 1)
       , rot_labels = c(top = -20))
```

## Mosaic Plot - Hair Marginal Totals

```{r emt}
mosaic(margin.table(haireye, 2)
       , shade = TRUE
       , split_vertical = TRUE
       , main="Eye Marginal Totals"
       , labeling = labeling_values
       , value_type = "observed"
       , gp_text = gpar(fontface = 1)
       , rot_labels = c(top = -20))
```


## Mosaic Plot - Expected Counts

```{r hr_expected}
# visualising expected counts for independent features
expected = independence_table(haireye)

mosaic(expected
      , shade = TRUE
      , main="Expected frequencies"
      , labeling = labeling_values
      , value_type = "expected"
      , gp_text = gpar(fontface = 1))
```

## Mosaic Plot - Observed Counts

```{r hr_actuals}
# visualising actual counts for independent features
mosaic(haireye
      , gp = shading_hcl # shade = TRUE
      , main="Actual frequencies"
      , labeling = labeling_values
      , value_type = "observed"
      , gp_text = gpar(fontface = 1))
```

## Mosaic Plot - Friendly Colour Scheme

```{r hr_actuals_friend}
# visualising actual counts for independent features
mosaic(haireye
      , gp = shading_Friendly # shade = TRUE
      , main="Actual frequencies"
      , labeling = labeling_values
      , value_type = "observed"
      , gp_text = gpar(fontface = 1))
```

## Previous + Sex Feature: Now in 3D

```{r hec}
# showing all three dimensions
mosaic(HEC
      , gp = shading_Friendly # shade = TRUE
      , main="Actual frequencies"
      , labeling = labeling_values
      , value_type = "observed"
      , gp_text = gpar(fontface = 1), rot_labels = c(right = -45)) 
```

## What You See Depends on the Pivot

```{r hec2}
# with a different pivot
mosaic(aperm(HEC, 3:1)
      , gp = shading_Friendly # shade = TRUE
      , main="Actual frequencies"
      , labeling = labeling_values
      , value_type = "observed"
      , gp_text = gpar(fontface = 1), rot_labels = c(right = -45)) 
```

## Pass in an Expectation

We know Hair and Eye are interacting and expect it. We can "clean up" these residuals and see what remains.

```{r hec_joint_model}
# convert to frequency form
HEC_df <- as.data.frame(HEC)

# explanatory model, hair eye interaction
hec.glm <- glm(Freq~Hair*Eye+Sex, data=HEC_df, family = poisson)

mosaic(hec.glm
       , gp = shading_Friendly
       , formula = ~ Sex + Eye + Hair
       , residuals_type = "rstandard")
```

## Mosaic Plot in 4D - Who Survived the Titanic?

```{r titanic_mosaic}
mosaic(aperm(Titanic, c(4, 2, 1, 3))
      , gp = shading_Friendly # shade = TRUE
      , main="Who Died and Who Survived the Titanic?"
      , labeling = labeling_values
      , value_type = "observed"
      , gp_text = gpar(fontface = 1), rot_labels = c(right = -45))
```

## Mosaic in n-D - Faceting

```{r titanic_cotab, echo=FALSE}
# note; all defaults except the shading!
cotabplot(Titanic, gp = shading_Friendly)
```

## Mosaic - Summary

The final plot didn't render nicely on these slides. Screen real-estate at run time was used more efficiently.

Important points:

* Mosaic plots; area $\propto$ cell count
* Fill colour by size of deviance residual
* Option for outline colour by deviance residual sign
* Scales well to 4-D
* At least a further 2-D can elevate up to facet
* Allows visual exploration of n-way interactions

# Example Two: Clustering and Dimension Reduction with Correspondence Analysis

## What is Correspondence Analysis?

Think of CA as somewhere between correlation analysis and PCA but for categorical data.

Features and categories that change together, move together. Cells with the largest values have the strongest influence.

```{r correspond}
include_graphics("correspond.png", dpi = 225)
```

## Audience Viewing Data

Audience viewing data from Neilsen Media Research for the week starting November 6, 1995

It is a 3-D array cross-tabulating the viewing figures for three networks, between 8-11pm, Monday to Friday. The features and their levels are as follows:

```{r describe_tv, echo=FALSE}
tv_desc <- data.frame(No=1:3
                      , Name=c("Day", "Time", "Network")
                      , Levels=c("Monday, Tuesday, Wednesday, Thursday, Friday", "8, 9, 10", "ABC, CBS, NBC"))
kable(tv_desc)
```

```{r tv_dataprep}
data("TV", package = "vcdExtra")
# The original data is collected in 15 minutes slices.

# Convert 3-D array to a frequency data frame
# This has a row for each cell of the array
# and a new column for the cell value
TV.df <- as.data.frame.table(TV)

# Convert it into hourly slices
levels(TV.df$Time) <- rep(c("8", "9", "10"), c(4,4,3))

# Convert frequency data back to 3-D array, now with just 3 time levels
TV3 <- xtabs(Freq~Day+Time+Network, TV.df)
```

## CA - A Cinch

```{r tv_3wayca, echo=TRUE}
# multiple CA - one line of code!
TV3.mca <- mjca(TV3)

# Flatten to 2-D by stacking time and day
TV3s <- as.matrix(structable(Network~Time+Day
                             , TV3))

# simple CA - one line of code!
TV3s.ca <- ca(TV3s)
```

## Other Considerations

Constructing a plot needs a little bit more work (not shown).

Really, just a little and all base R graphics.

When you've done it once, it's easy to customise for your needs.

Multiple and Joint CA examines relationships among all features at once and can be used for dimension reduction.

Simple CA only supports 2D data to start with. However, smart use of pivots can actually reveal more information because there are more free points. It will take a bit of trial and error.

## Multiple Correspondence Analysis Plot

```{r TV_mca_plot, fig.width=6, fig.height=5}
# the plot function uses all base R plot stuff
# but needs a bit of manipulation
cols <- c("blue", "black", "red")

# "blank plot"
res <- plot(TV3.mca, labels=0, pch='.', cex.lab=1.2)

# combine Dims, factor names and levels
coords <- data.frame(res$cols, TV3.mca$factors)

# hard-coded from known number of levels
# day, time, network
nlev <- c(5,3,3)

# everything needs to be in semantic order
coords <- coords[ order(coords[,"factor"], coords[,"level"]), ]
# quick fix for ordering e.g. day of week, not alphabetical
coords$order <- c(5, 1, 4, 2, 3, 6, 7, 8, 11, 9, 10)
coords <- coords[order(coords[, "order"]), ]

# place the points with separate plot chars and colours
points(coords[,1:2], pch=rep(16:18, nlev), col=rep(cols, nlev), cex=1.2)

# place the text
pos <- c(1,4,3)
text(coords[,1:2], labels=coords$level, col=rep(cols, nlev), pos=rep(pos,nlev), cex=1.1, xpd=TRUE)

# join things in sequence
lines(Dim2 ~ Dim1, data=coords, subset=factor=="Day", lty=1, lwd=1, col="blue")
lines(Dim2 ~ Dim1, data=coords, subset=factor=="Time",  lty=1, lwd=1, col="red")

# add segement from the origin to channels
nw <- subset(coords, factor=="Network")
segments(0, 0, nw[,"Dim1"], nw[, "Dim2"], col = "black", lwd = 0.5, lty = 3)

# add a legend
legend("topright", legend=c("Day", "Network", "Time"),
       title="Factor", title.col="black",
       col=cols, text.col=cols, pch=16:18,
       bg="gray95")
```

## CA Converts Categorical to Continuous

Order is NOT arbitrary!

```{r res_coords}
coords[ order(coords[,"factor"], -coords[,"Dim1"]), c("Dim1", "Dim2")]
```

## Simple Correspondence Analysis Plot

```{r TV.ca, fig.width=6, fig.height=5}
# Generate the plot
res <- plot(TV3s.ca)
# add some segments from the origin to make things clearer
segments(0, 0, res$cols[,1], res$cols[,2], col = "red", lwd = 1)
segments(0, 0, res$rows[,1], res$rows[,2], col = "blue", lwd = 0.5, lty = 3)
```

## Multiple Correspondence Analysis Plot in 4-D

```{r Titanic_mca}
# one more mca from a 4-D dataset
# this is simpler than it looks
# all the magic happens here
titanic.mca <- mjca(Titanic)

# saving the plot object supplies the coordinate positions
res <- plot(titanic.mca, labels=0, pch='.', cex.lab=1.2)

# extract factor names and levels
coords <- data.frame(res$cols, titanic.mca$factors)

# everything else is handling base R plotting stuff
cols <- c("blue", "red", "brown", "black")
nlev <- c(4,2,2,2)
points(coords[,1:2], pch=rep(16:19, nlev), col=rep(cols, nlev), cex=1.2)
pos <- c(3,1,1,3)
text(coords[,1:2], labels=coords$level, col=rep(cols, nlev), pos=rep(pos,nlev), cex=1.1, xpd=TRUE)
coords <- coords[ order(coords[,"factor"], coords[,"Dim1"]), ]
lines(Dim2 ~ Dim1, data=coords, subset=factor=="Class", lty=1, lwd=2, col="blue")
lines(Dim2 ~ Dim1, data=coords, subset=factor=="Sex",  lty=1, lwd=2, col="red")
lines(Dim2 ~ Dim1, data=coords, subset=factor=="Age",  lty=1, lwd=2, col="brown")
lines(Dim2 ~ Dim1, data=coords, subset=factor=="Survived",  lty=1, lwd=2, col="black")

legend("topleft", legend=c("Class", "Sex", "Age", "Survived"),
       title="Factor", title.col="black",
       col=cols, text.col=cols, pch=16:19,
       bg="gray95", cex=1.2)
```

## Correspondence Analysis - Summary

* CA is a very powerful technique based on matrix decomposition
* Offers additional perspective for exploring data
* Complex, non-parametric relationships are easily visualised can be explored
* Useful for reducing dimensions
* Converting categorical dimensions to continuous, while preserving information
* Sort data by CA dimension rather than natural ordering: [*Monday, Tuesday, Wednesday, Thursday, Friday*] $\nRightarrow$ [*1,2,3,4,5*]

# Example Three: Slicing a Confusion Matrix by Important Features

## Overview - The Nursery Data Set

Four possible classes

Three evenly balanced 

Fourth is a tiny minority class

All the predictors are discrete

A random forest is trained on 70% of the data and evaluated on the remaining 30%

***

```{r nursery_data}
set.seed(54321)
nursery <- read.csv(gzfile("nursery.csv.gz"))
summary(nursery)
```

***

```{r nursery_randfor}
# train test split
idx <- sample(c(TRUE, FALSE)
              , size = nrow(nursery)
              , prob = c(0.7, 0.3)
              , replace = TRUE)

nurs_train <- nursery[idx, ]
nurs_test <- nursery[!idx, ]

# train rf accepting all the defaults
nurs_rf <- randomForest(decision~., data=nurs_train)

# get the predictions on new data
nurs_preds <- predict(nurs_rf, newdata = nurs_test)

# confusion matrix
confmat <- with(nurs_test, table(nurs_preds, decision))
confmat
```

## Tile Plot of Confusion Matrix

```{r nurs_cm_tile}
tile(confmat, labeling = labeling_values)
```

## Variable Importance Plots

Important in what way?

What does anyone do with this information?

```{r nurs_varimp, fig.height=4}
varImpPlot(nurs_rf)
```

Note the elbow. Could we do without half the features?

## Confusion Matrix By health == "recommended"

```{r nurs_cm_health}
cm_3d <- with(nurs_test
              , table(nurs_preds, decision, health))

re <- cm_3d[,,"recommended"]
tile(re, labeling = labeling_values)
```

## Confusion Matrix By health == "priority"

```{r}
pr <- cm_3d[,,"priority"]
tile(pr, labeling = labeling_values)
```

## Confusion Matrix By health == "not_recom"

```{r}
nr <- cm_3d[,,"not_recom"]
tile(nr, labeling = labeling_values)
```

## What Makes A Variable Important? - Revisited

health feature - very important, and now we know why

health == "not_recom" is a useful decision stump: take outside model?

Thorough EDA should find this prior to modeling

## Applied to Binary Classification

This situation can't come about during binary classification. One feature would be a perfect representation of target.

Can this technique still help?

## Binary Classification $2 \times 2$ Table

Special case $2 \times 2$ table

vcd has a fourfold plot function: compares odds ratios by standardising pie areas

Force the fourfold to represent counts on the radius: 

$$\mathit{count} \propto \sqrt{\mathit{area}}$$

fourfold also automatically stratifies by a third variable! Just a snippet of code required.

This is a very nifty shortcut! vcd always wants to preserve the given table structure. Any other plotting method could not be done in one line of code.

## German Data Set - Credit Rating

A mix of discrete and continuous. Target is rating: "bad" (30%) or "good" (70%)

A predicted bad rating on a true bad rating - True Positive

A predicted good rating on a true bad rating - False Negative

Very high cost per False Negative: Offer of credit to a likely defaulter!

Random Forest can only optimise 0-1 loss

Training data is balanced by over sampling.

***

```{r german_randfor}
german <- read.csv(gzfile("german.csv.gz"))

set.seed(54321)
# train test split
idx <- sample(c(TRUE, FALSE)
              , size = nrow(german)
              , prob = c(0.7, 0.3)
              , replace = TRUE)

german_train <- german[idx, ]
german_test <- german[!idx, ]

# make the training data balanced in case over fits good
# originally 300 bad, 700 good
german_train <- ovun.sample(rating~.
                      , data=german_train
                      , method = "over"
                      , p = 0.5)$data

# restore the factor levels to correct order
german_train$rating <- relevel(german_train$rating, "bad") 

# train rf accepting all the defaults
german_rf <- randomForest(rating~., data=german_train)

# get the predictions on new data
german_preds <- predict(german_rf, newdata = german_test)

# confusion matrix
confmat <- with(german_test, table(german_preds, rating))
confmat
```

***

```{r main_cm_stats, echo=TRUE}
# accuracy
sum(diag(confmat))/sum(confmat)

# False Negative Rate FN / (TP + FN)
confmat[2, 1]/sum(confmat[, 1])

# False Ommision Rate FN / (TN + FN)
confmat[2, 1]/sum(confmat[2, ])
```

***

```{r main_cm_rose, echo=TRUE, fig.width=4.5, fig.height=4.5}
# std = "all.max" suppresses balancing the areas
# behaves like a rose plot
fourfold(confmat, std = "all.max")
```

***

```{r german_varimp}
varImpPlot(german_rf)
```

## Fourfold Rose Plot - Confidence Matrix By chk

```{r rose_setup}
my_rose <- function(cm) {
  fourfold(cm
         , std = "all.max" # mimic a 4 way rose plot
         , conf_level = 0 # suppress confint tests, not useful here
         , color = c("#FF0000", "#000080") # need to force colours due to suppressing confint test
         )
}

# fourfold automatically stratifies by third (and fourth) level of n-dim table

# this is the only code required for the plots you will see next
confmat_c <- with(german_test
                  , table(german_preds
                          , rating
                          , chk))

my_rose(confmat_c)
```

## This method REALLY scales!

```{r rose_pps}
confmat_p <- with(german_test
                  , table(german_preds
                          , rating
                          , pps))

my_rose(confmat_p)
```

## Integer Valued Feature with 22 Unique Values

```{r my_rose_dur}
confmat_d <- with(german_test
                  , table(german_preds
                          , rating
                          , dur))
my_rose(confmat_d)
```

## 2 & 3-Way Interactions Possible - Log Odds Ratio

The odds ratio for the binary confusion matrix conveniently rearranges to:

$$\phi = \log\Big(\frac{\mathrm{TP} \times \mathrm{TN}}{\mathrm{FP} \times \mathrm{FN}}\Big)$$

Note, all the T in the numerator and all the F in the denominator. 

Very easy to interpret:

* $\phi \in \mathbb{R}^+$ is good but check confidence intervals
* $\phi > 3 \implies$ ratio of T:F $\approx 20:1$

Bonus: confidence intervals!

***

```{r lodds}
# higher dimensional
confmat_ce <- with(german_test
                   , table(german_preds
                           , rating
                           , chk
                           , emp))

confmat_ce <- with(german_test
                   , table(german_preds
                           , rating
                           , chk
                           , emp))
plot(loddsratio(confmat_ce), confidence = FALSE)
```

## Slicing a Confusion Matrix Summary

Important points:

* Use whenever you have suitable categorical variables
* Feature importance measure; a helpful guide but not essential.
* Drill into sources of bias
* Rose plots are intuitive for $2 \times 2$ tables and easy to produce
* vcd fourfold scales to tens of levels on one category
* Explore 2 and 3-way interactions with log odds ratios 
* Log odds ratios compromise clarity on accuracy measures such as FNR

# Example Four: Handling Ordinal Classification Correctly

## MSPatients Overview

Two Neurologists diagnose the same 218 patients on a severity scale

This is an inter-rater agreement table. We'll pretend it's a confusion matrix. Classes not completely balanced.

## Baseline Score

```{r MSP_2D}
# combine results from two cities (same raters are involved in all cases)
MSP <- margin.table(MSPatients, 1:2)
class_names <- c("Certain",  "Probable", "Possible", "Doubtful")
dimnames(MSP) <- list(prd = class_names
                      , tru = class_names)
```

```{r MSP_winntrue}
margin.table(MSP, 2)
props <- prop.table(margin.table(MSP, 2))
props

# Baseline accuracy: A constant-guess machine for majority class
props[which(props == max(props))]

# Actual accuracy (prior to viewing the table)
cat("Accuracy - sum(diag)/total")
sum(diag(MSP))/sum(MSP)
```

## The MSP Confusion Matrix

```{r MSP_confmat}
MSP
```

Obviously it's not a constant model and doesn't look like a random guess. So what's wrong?

Check Cohen's $\kappa$ to correct for class imbalance

```{r kappa}
confint(Kappa(MSP, weights = "Fleiss-Cohen"))
```

Weighted indicates that off-by-n errors are important

## Agreement Plot

```{r agreement, fig.height=5, fig.width=5}
op <- par(mar = c(4, 3, 4, 1) + .1)
B <- agreementplot(MSP
                   , main = "MS Patient Ratings"
                   , xlab_rot = -20
)

par(op)
```

## Handling Ordinal Classification - Summary

* Ordinal classification is a special case
* Near disagreement needs to be weighted
* Weighted $\kappa$ and Bangdiwala stats useful
* Agreement plot is ideal
* Plot reveals differences in inter-rater marginal totals, where statistics are insensitive

# It's easy to rush into using the latest tools and technologies. Most Machine Learning is based on years of statistical research. That work is still just as relevant as ever. It's worth reflecting on tried and tested techniques that might easily address today's challenges. 

# End